# Tiny Transformer (Coming Jan 2026)

This repo will contain a minimal Transformer implementation written from scratch in PyTorch, building out:

- Multi-head attention  
- Feedforward blocks  
- Positional embeddings  
- Training loop  
- Tokenization pipeline  
- Text generation  

This project is part of my ML Engineer preparation roadmap.
